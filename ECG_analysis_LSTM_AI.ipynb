{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_analysis_AI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pXSVAskKO3Osi7is_FQFoFHpVLvVpsXE",
      "authorship_tag": "ABX9TyPmCz5f3kVwl6nFNbVIHy/Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgkim-developer/INU-Lab/blob/master/ECG_analysis_LSTM_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aott6TbfQmyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "9fc54b28-4c33-4810-84b9-dc27272d63d5"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras. layers import Dense, Activation, Dropout\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab_Data/heartbeat_datasets_edit2.csv')\n",
        "df.isnull().sum()\n",
        "print(df.values.shape)\n",
        "\n",
        "dataset = df.values\n",
        "print(dataset)\n",
        "\n",
        "x = dataset[:, 0:-1]\n",
        "y = dataset[:, -1]\n",
        "\n",
        "x_train = x[:189]\n",
        "y_train = y[:189]\n",
        "\n",
        "x_val = x[189:243]\n",
        "y_val = y[189:243]\n",
        "\n",
        "x_test = x[243:]\n",
        "y_test = y[243:]\n",
        "\n",
        "print(x_test[:10])\n",
        "\n",
        "\n",
        "\n",
        "# #정규화\n",
        "\n",
        "x_train = x_train.reshape(189, 986).astype('float32')/1620.0\n",
        "x_val = x_val.reshape(54, 986).astype('float32')/1620.0\n",
        "x_test = x_test.reshape(27, 986).astype('float32')/1620.0\n",
        "\n",
        "#data handling\n",
        "x_train = np.reshape(x_train, (189, 986, 1))\n",
        "x_val = np.reshape(x_val, (54, 986, 1))\n",
        "x_test = np.reshape(x_test, (27, 986, 1))\n",
        "\n",
        "# x_train = np.reshape(x_train, (x_train.shape[0[0], x_train.shape[1],))\n",
        "# x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],3))\n",
        "\n",
        "#data 구성\n",
        "model = Sequential()\n",
        "model.add( LSTM(32, input_shape = (986,1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add( Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add( Dense(32, activation = 'relu'))\n",
        "model.add( Dense(16, activation = 'relu'))\n",
        "model.add( Dense(3, activation = 'softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(270, 986)\n",
            "[[970 950 970 ... 950 950 'Baseline']\n",
            " [760 740 750 ... 240 240 'VT']\n",
            " [940 780 780 ... 700 700 'Baseline']\n",
            " ...\n",
            " [490 1140 820 ... 270 280 'VT']\n",
            " [1070 1040 1050 ... 1200 1170 'Baseline']\n",
            " [740 590 920 ... 320 290 'VT']]\n",
            "[[610 580 590 ... 300 320 290]\n",
            " [780 810 800 ... 790 800 790]\n",
            " [750 740 750 ... 360 320 340]\n",
            " ...\n",
            " [940 960 950 ... 1080 1070 1030]\n",
            " [580 580 590 ... 350 360 360]\n",
            " [740 760 580 ... 1030 1050 980]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1e6dc6ef299d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# #정규화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m189\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m986\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1620.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m986\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1620.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m986\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1620.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 186165 into shape (189,986)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV7r2CMde19o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "de9e5f42-b502-4aa2-b679-436bc73a7b85"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping \n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, datasets \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab_Data/heartbeat_datasets.csv')\n",
        "print(df.values.shape)\n",
        "\n",
        "dataset = df.values\n",
        "print(dataset)\n",
        "\n",
        "X = dataset[:, 0:-1]\n",
        "y = dataset[:, -1]\n",
        "\n",
        "x_train = X[:189]\n",
        "y_train = y[:189]\n",
        "\n",
        "x_val = X[189:243]\n",
        "y_val = y[189:243]\n",
        "\n",
        "x_test = X[243:]\n",
        "y_test = y[243:]\n",
        "\n",
        "print(x_test[:10])\n",
        "\n",
        "# 2. 정규화\n",
        "x_train = x_train.reshape(189, 986).astype('float32')/1620.0\n",
        "x_val = x_val.reshape(54, 986).astype('float32')/1620.0\n",
        "x_test = x_test.reshape(27, 986).astype('float32')/1620.0\n",
        "\n",
        "# print(x_train.shape)\n",
        "x_train = np.reshape(x_train, (189, 986, 1))\n",
        "x_val = np.reshape(x_val, (54, 986, 1))\n",
        "x_test = np.reshape(x_test, (27, 986, 1))\n",
        "\n",
        "# x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],))\n",
        "# x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],3))\n",
        "\n",
        "# 3. 모델 구성\n",
        "model = Sequential()\n",
        "model.add( LSTM(32, input_shape = (986, 1)))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add( Dense(64, activation = 'relu')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add( Dense(32, activation = 'relu'))\n",
        "model.add( Dense(16, activation = 'relu'))\n",
        "model.add( Dense(3, activation = 'softmax'))\n",
        "\n",
        "# 4. model compile\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "\n",
        "# 5. 학습의 자동중단 10번동안 나아지지 않으면 stop\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "# 6. 모델 학습\n",
        "hist = model.fit(x_train, y_train, epochs=500, batch_size=32, validation_data=(x_val, y_val),callbacks=[early_stop])\n",
        "\n",
        "# 7. 모델 학습 과정 표시하기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 8. 결과\n",
        "\n",
        "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1)\n",
        "print('loss : ' + str(loss_and_metrics[0])) \n",
        "results = model.evaluate(x_test, y_test)\n",
        "print('acc:', results[1]*100,'%')\n",
        "\n",
        "predicts= model.predict(x_test)\n",
        "# 9. 예측한 값 분류화 \n",
        "result = model.predict_classes(x_test, verbose=0)\n",
        "print(\"예측값 softmax 적용\\n\", predicts[:10] )\n",
        "print(\"\\n클래스예측\\n\", result[:10])\n",
        "print(\"\\n실제값\\n\", y_test[:10])\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=60).create(prog='dot', format='svg'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-55039d516959>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from keras.utils import np_utils\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMfwFfqve4q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}